# ML Disaster Tweets â€” NLP Classification

Proyecto de Machine Learning y Procesamiento de Lenguaje Natural (NLP) cuyo objetivo es
clasificar tweets segÃºn si refieren a un desastre real o no, utilizando distintos enfoques
de modelado y feature engineering.

El trabajo se basa en la competencia de Kaggle  
**Natural Language Processing with Disaster Tweets**  
https://www.kaggle.com/competitions/nlp-getting-started

---

## ğŸ“Œ Objetivo

Dado un conjunto de tweets, predecir si el contenido estÃ¡ basado en un hecho real
(`target = 1`) o no (`target = 0`), utilizando tÃ©cnicas de Machine Learning supervisado
y NLP.

---

## ğŸ“Š Dataset

El dataset provisto por Kaggle contiene las siguientes columnas:

- `id`: identificador Ãºnico del tweet  
- `text`: texto del tweet  
- `location`: ubicaciÃ³n desde donde fue enviado (opcional)  
- `keyword`: palabra clave asociada al tweet (opcional)  
- `target`: variable objetivo (solo en `train.csv`)  

---

## ğŸ§ª Estructura del Proyecto

El trabajo fue desarrollado de manera modular y reproducible, separando cada etapa
en notebooks independientes:

- **Exploratory Data Analysis (EDA)**  
  Visualizaciones para analizar la relaciÃ³n entre las variables y el target.

- **Baseline Model**  
  Modelo de regresiÃ³n logÃ­stica con features numÃ©ricas y categÃ³ricas, utilizado como
  referencia inicial.

- **Machine Learning Models**  
  Entrenamiento de modelos mÃ¡s complejos con bÃºsqueda de hiperparÃ¡metros y validaciÃ³n
  basada en F1-score.

---

## ğŸ” Parte I â€” AnÃ¡lisis Exploratorio

- AnÃ¡lisis del target y su distribuciÃ³n
- Visualizaciones explicativas y legibles
- RelaciÃ³n entre keywords, longitud del texto y ocurrencia de desastres

---

## âš™ï¸ Parte II â€” Baseline Model

- RegresiÃ³n logÃ­stica
- Features numÃ©ricas y categÃ³ricas
- Embedding del texto
- BÃºsqueda de hiperparÃ¡metros
- ValidaciÃ³n reproducible
- AnÃ¡lisis de importancia de features

Este modelo se utilizÃ³ como referencia para evaluar la complejidad del problema y
comparar el desempeÃ±o de modelos mÃ¡s avanzados.

---

## ğŸ¤– Parte III â€” Modelos de Machine Learning

Se entrenaron distintos modelos (excluyendo regresiÃ³n logÃ­stica), cumpliendo las
siguientes condiciones:

- MÃ©trica de validaciÃ³n: **F1-score**
- ValidaciÃ³n independiente del set de test
- Reproducibilidad garantizada
- Feature engineering con:
  - One-Hot Encoding
  - Mean Encoding
- Resultados superiores a **0.80 de F1 en validaciÃ³n**

Para los mejores modelos se analizaron:
- Curva ROC
- Matriz de confusiÃ³n
- Importancia de features

---

## ğŸš€ Parte IV â€” Extensiones

Como parte adicional del trabajo, se exploraron enfoques avanzados como:

- ReducciÃ³n del nÃºmero de features manteniendo alto desempeÃ±o
- Modelos con embeddings de texto
- VisualizaciÃ³n de embeddings mediante tÃ©cnicas de reducciÃ³n de dimensionalidad

---

## ğŸ“ˆ Resultados

Los modelos desarrollados alcanzaron un desempeÃ±o competitivo tanto en validaciÃ³n
como en la competencia de Kaggle, demostrando la efectividad del feature engineering
y la selecciÃ³n de modelos.

Los archivos de predicciÃ³n (`submission.csv`) fueron generados siguiendo el formato
requerido por la competencia.

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- Python
- Pandas, NumPy
- Scikit-learn
- NLP & Text Preprocessing
- Kaggle Notebooks

---

## ğŸ“š Contexto AcadÃ©mico

Trabajo PrÃ¡ctico N.Âº 3 â€” **Ciencia de Datos**  
CÃ¡tedra Martinelli  
Universidad de Buenos Aires

---

## âœï¸ Autor

**Manuel Pueyrredon**  
Estudiante de IngenierÃ­a InformÃ¡tica (UBA)  
GitHub: https://github.com/ManuPueyUba
